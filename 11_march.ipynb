{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QFnWIKcTxBcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e88af429-2b39-4425-ce30-e290af7df92a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A t-test and a z-test are both statistical tests used to compare two groups of data. \\nThe main difference between the two tests is that the t-test is used when the population standard deviation is unknown,\\n while the z-test is used when the population standard deviation is known.\\nAnother difference between the two tests is that the t-test is more robust to violations of the assumption of normality than the z-test. \\nThis means that the t-test can still be used even if the data is not perfectly normally distributed, while the z-test should not be used \\nif the data is not normally distributed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#What is the difference between a t-test and a z-test? Provide an example scenario where you would use each type of test.\n",
        "\n",
        "\"\"\"A t-test and a z-test are both statistical tests used to compare two groups of data.\n",
        "The main difference between the two tests is that the t-test is used when the population standard deviation is unknown,\n",
        " while the z-test is used when the population standard deviation is known.\n",
        "Another difference between the two tests is that the t-test is more robust to violations of the assumption of normality than the z-test.\n",
        "This means that the t-test can still be used even if the data is not perfectly normally distributed, while the z-test should not be used\n",
        "if the data is not normally distributed\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Differentiate between one-tailed and two-tailed tests.\n",
        "\n",
        "\n",
        "\"\"\"The main difference between one-tailed and two-tailed tests is that one-tailed tests will only have one critical region whereas\n",
        "two-tailed tests will have two critical regions\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "v31KAvqSzuPn",
        "outputId": "6a10885e-dcb5-41e1-8176-6a7897974136"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The main difference between one-tailed and two-tailed tests is that one-tailed tests will only have one critical region whereas \\ntwo-tailed tests will have two critical regions'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for each type of error.\n",
        "\n",
        "\"\"\"in hypothesis testing, type I errors, also known as false positives, occur when the null hypothesis is rejected even though it is true.\n",
        "For example, if an innocent person is convicted of a crime, that is a type I error. Type II errors, also known as false negatives, occur when\n",
        "the null hypothesis is not rejected even though it is false. For example, if a guilty person is not convicted, that is a type II error\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3PFrqka_0IDk",
        "outputId": "07abdd15-8665-4c0d-b8bc-bf6967835abd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in hypothesis testing, type I errors, also known as false positives, occur when the null hypothesis is rejected even though it is true. \\nFor example, if an innocent person is convicted of a crime, that is a type I error. Type II errors, also known as false negatives, occur when \\nthe null hypothesis is not rejected even though it is false. For example, if a guilty person is not convicted, that is a type II error'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explain Bayes's theorem with an example.\n",
        "\n",
        "\"\"\"a probability theory formula that describes the likelihood of an event based on previous knowledge of related conditions.\n",
        "For example, if the risk of developing health issues increases with age, Bayes' theorem can help assess an individual's risk based on their age,\n",
        "rather than assuming the individual is typical of the population at large\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "SHuGrnEA5FcE",
        "outputId": "ecb36554-1431-48aa-c0a6-6de23f1f8062"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"a probability theory formula that describes the likelihood of an event based on previous knowledge of related conditions. \\nFor example, if the risk of developing health issues increases with age, Bayes' theorem can help assess an individual's risk based on their age, \\nrather than assuming the individual is typical of the population at large\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is a confidence interval? How to calculate the confidence interval, explain with an example.\n",
        "\n",
        "\"\"\"A confidence interval is a range of values that may contain an unknown parameter, such as the population mean, with a known level of certainty\n",
        "\n",
        "The confidence interval (CI) is calculated by taking the set value multiplied by the standard deviation, and then dividing by the root of the number of\n",
        "patients. The set value can be derived from a table that shows which area is contained in the CI. For example, if a sample of 1,000 patients has a\n",
        "change in shoulder range of motion of 14 degrees with a standard deviation of 5 degrees, the CI can be calculated as follows:\n",
        "CI: = 80.5 ± 0.95(32.25 ÷ √10\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "gydkE9DY6Jpx",
        "outputId": "27ce928b-439d-432f-f1ff-d2ff78ff6426"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A confidence interval is a range of values that may contain an unknown parameter, such as the population mean, with a known level of certainty\\n\\nThe confidence interval (CI) is calculated by taking the set value multiplied by the standard deviation, and then dividing by the root of the number of \\npatients. The set value can be derived from a table that shows which area is contained in the CI. For example, if a sample of 1,000 patients has a \\nchange in shoulder range of motion of 14 degrees with a standard deviation of 5 degrees, the CI can be calculated as follows:\\nCI: = 80.5 ± 0.95(32.25 ÷ √10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Bayes' Theorem to calculate the probability of an event occurring given prior knowledge of the event's probability and new evidence. Provide a sample problem and solution.\n",
        "\n",
        "\n",
        "\"\"\"Imagine you have a basket containing 10 apples, 5 of which are red and 5 are green. You randomly pick an apple without looking (so each apple has an equal chance of being picked). You don't look at the apple you pick, but you sense it's not red. What's the probability the apple you picked is green?\n",
        "\n",
        "Solution\n",
        "\n",
        "Let's define the events:\n",
        "\n",
        "Event A: Picking a red apple\n",
        "Event B: Picking an apple that's not red (i.e., green)\n",
        "We are interested in P(B|A), the probability of picking a green apple (B) given that it's not red (A).\n",
        "\n",
        "P(A) = 0.5 (There are 5 red apples out of 10 total)\n",
        "P(B|A) = 0 (If you already picked a red apple, it can't be green)\n",
        "P(B) = The probability of picking an apple that's not red (which is the same as picking a green apple in this case). Since there are 5 green apples, P(B) = 0.5\n",
        "Applying Bayes' theorem:\n",
        "\n",
        "P(B|A) = (P(A|B) * P(A)) / P(B) = (0 * 0.5) / 0.5 = 0\n",
        "As expected, the probability of picking a green apple after you've realized it's not red is 0 (since you already know it's not red). This might seem counterintuitive at first, but it highlights how Bayes' theorem updates probabilities based on new information\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "0jOG2ti96iox",
        "outputId": "cc267064-faf1-498d-9726-cfa608ad4df0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Imagine you have a basket containing 10 apples, 5 of which are red and 5 are green. You randomly pick an apple without looking (so each apple has an equal chance of being picked). You don't look at the apple you pick, but you sense it's not red. What's the probability the apple you picked is green?\\n\\nSolution\\n\\nLet's define the events:\\n\\nEvent A: Picking a red apple\\nEvent B: Picking an apple that's not red (i.e., green)\\nWe are interested in P(B|A), the probability of picking a green apple (B) given that it's not red (A).\\n\\nP(A) = 0.5 (There are 5 red apples out of 10 total)\\nP(B|A) = 0 (If you already picked a red apple, it can't be green)\\nP(B) = The probability of picking an apple that's not red (which is the same as picking a green apple in this case). Since there are 5 green apples, P(B) = 0.5\\nApplying Bayes' theorem:\\n\\nP(B|A) = (P(A|B) * P(A)) / P(B) = (0 * 0.5) / 0.5 = 0\\nAs expected, the probability of picking a green apple after you've realized it's not red is 0 (since you already know it's not red). This might seem counterintuitive at first, but it highlights how Bayes' theorem updates probabilities based on new information\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Sample mean and standard deviation\n",
        "mean = 50\n",
        "std_dev = 5\n",
        "\n",
        "# Calculate z-scores for 95% confidence interval\n",
        "z_crit = stats.norm.ppf(0.975)  # 2.5% in each tail\n",
        "\n",
        "# Confidence interval lower and upper bounds\n",
        "lower_bound = mean - z_crit * std_dev\n",
        "upper_bound = mean + z_crit * std_dev\n",
        "\n",
        "# Print the confidence interval\n",
        "print(f\"95% confidence interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"Interpretation: We are 95% confident that the true population mean lies within this interval.\")\n",
        "print(\"In other words, if we were to repeat this sampling process many times and calculate the confidence interval for each sample, 95% of those intervals would contain the true population mean.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysXZsrpGFpqk",
        "outputId": "d7b300b8-6181-4b5b-caa5-d2726433d3e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% confidence interval: (40.20, 59.80)\n",
            "Interpretation: We are 95% confident that the true population mean lies within this interval.\n",
            "In other words, if we were to repeat this sampling process many times and calculate the confidence interval for each sample, 95% of those intervals would contain the true population mean.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the margin of error in a confidence interval? How does sample size affect the margin of error?\n",
        "#  Provide an example of a scenario where a larger sample size would result in a smaller margin of error.\n",
        "\n",
        "\n",
        "\"\"\"Margin error = the margin of error is a measure of the precision of a point estiamte, indicating the maximum amount it could be off from the true population\n",
        "parameter,with a ceratin level of parameter.\n",
        "\n",
        "In general, a larger sample size decreases the margin of error. This is because a larger sample size better represents the population, which results in a smaller sample standard error\n",
        "\n",
        "In statistics, sample size and margin of error have an inverse relationship. For example, a survey with 100 respondents may have a larger\n",
        "margin of error than a survey with 1,000 respondents. This is because larger sample sizes result in smaller sampling errors.\n",
        "For example, increasing the sample size from 1,500 to 2,000 decreases the margin of error by 0.34%. However, after a certain point,\n",
        "increasing the sample size beyond that point gives a diminished return\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "V8poUGQcGRt6",
        "outputId": "e5123910-22f3-4988-e4cd-f03107498e45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Margin error = the margin of error is a measure of the precision of a point estiamte, indicating the maximum amount it could be off from the true population \\nparameter,with a ceratin level of parameter. \\n\\nIn general, a larger sample size decreases the margin of error. This is because a larger sample size better represents the population, which results in a smaller sample standard error\\n\\nIn statistics, sample size and margin of error have an inverse relationship. For example, a survey with 100 respondents may have a larger \\nmargin of error than a survey with 1,000 respondents. This is because larger sample sizes result in smaller sampling errors. \\nFor example, increasing the sample size from 1,500 to 2,000 decreases the margin of error by 0.34%. However, after a certain point, \\nincreasing the sample size beyond that point gives a diminished return'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "population_m = 75\n",
        "sample_m = 70\n",
        "std_d = 5\n",
        "\n",
        "Z_score = (population_m - sample_m)/std_d\n",
        "\n",
        "print(Z_score)\n",
        "\n",
        "if Z_score > 1.96:\n",
        "    print(\"Interpretation: The data point is more than 1.96 standard deviations above the population mean, indicating a relatively high value.\")\n",
        "elif Z_score < -1.96:\n",
        "    print(\"Interpretation: The data point is more than 1.96 standard deviations below the population mean, indicating a relatively low value.\")\n",
        "else:\n",
        "    print(\"Interpretation: The data point is within 1.96 standard deviations of the population mean, considered neither exceptionally high nor low.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptrYOH0hIR_Q",
        "outputId": "a471573e-9606-4e6d-a0fc-14bfc6dbfab5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Interpretation: The data point is within 1.96 standard deviations of the population mean, considered neither exceptionally high nor low.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Sample data\n",
        "mean_A = 85\n",
        "std_dev_A = 6\n",
        "n_A = 100\n",
        "\n",
        "mean_B = 82\n",
        "std_dev_B = 5\n",
        "n_B = 100\n",
        "\n",
        "# Calculate t-statistic and p-value\n",
        "t_stat, p_value = stats.ttest_ind_from_stats(mean_A, std_dev_A, n_A, mean_B, std_dev_B, n_B)\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.01\n",
        "\n",
        "# Compare p-value with alpha\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in student performance between the two teaching methods.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in student performance between the two teaching methods.\")\n",
        "\n",
        "\n",
        "\n",
        "# Sample size\n",
        "n = 500\n",
        "\n",
        "# Sample proportion (people satisfied with job)\n",
        "p_hat = 0.65\n",
        "\n",
        "# Confidence level (95%)\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Calculate the margin of error\n",
        "alpha = 1 - confidence_level\n",
        "z_critical = np.abs(np.quantile(np.random.standard_normal(size=10000), 1 - alpha / 2))\n",
        "\n",
        "# Calculate the confidence interval\n",
        "margin_of_error = z_critical * np.sqrt(p_hat * (1 - p_hat) / n)\n",
        "lower_bound = p_hat - margin_of_error\n",
        "upper_bound = p_hat + margin_of_error\n",
        "\n",
        "# Print the confidence interval\n",
        "print(f\"The 95% confidence interval for the true proportion of people satisfied with their job is: ({lower_bound:.4f}, {upper_bound:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzU8dPEeSTRR",
        "outputId": "39427add-5fee-414a-fddf-385b86382c6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reject the null hypothesis. There is a significant difference in student performance between the two teaching methods.\n",
            "The 95% confidence interval for the true proportion of people satisfied with their job is: (0.6084, 0.6916)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 65\n",
        "sample_std_dev = 8\n",
        "sample_size = 50\n",
        "confidence_level = 0.90\n",
        "\n",
        "# Calculate the standard error of the mean\n",
        "standard_error = sample_std_dev / math.sqrt(sample_size)\n",
        "\n",
        "# Calculate the critical value (z-score) for the given confidence level\n",
        "confidence_level_z = stats.norm.ppf((1 + confidence_level) / 2)\n",
        "\n",
        "# Calculate the margin of error\n",
        "margin_of_error = confidence_level_z * standard_error\n",
        "\n",
        "# Calculate the lower and upper bounds of the confidence interval\n",
        "lower_bound = sample_mean - margin_of_error\n",
        "upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "# Print the confidence interval\n",
        "print(f\"90% Confidence Interval: ({lower_bound:.3f}, {upper_bound:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3U6558aiWCX",
        "outputId": "d2b0ba7f-7d59-4b43-cee4-59829418f347"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90% Confidence Interval: (63.139, 66.861)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import math\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 0.25\n",
        "sample_std_dev = 0.05\n",
        "sample_size = 30\n",
        "confidence_level = 0.90\n",
        "\n",
        "# Calculate the standard error of the mean\n",
        "standard_error = sample_std_dev / math.sqrt(sample_size)\n",
        "\n",
        "# Calculate the t-statistic\n",
        "t_stat = (sample_mean - 0) / standard_error\n",
        "\n",
        "# Calculate the critical t-value\n",
        "degrees_of_freedom = sample_size - 1\n",
        "critical_t_value = stats.t.ppf((1 + confidence_level) / 2, df=degrees_of_freedom)\n",
        "\n",
        "# Compare t-statistic with critical t-value\n",
        "if abs(t_stat) > critical_t_value:\n",
        "    print(\"Reject the null hypothesis. Caffeine has a significant effect on reaction time.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Caffeine does not have a significant effect on reaction time.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEfNKM9Nlj-4",
        "outputId": "5965e2ac-89ee-43db-d8c4-763eecde21d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reject the null hypothesis. Caffeine has a significant effect on reaction time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekks-vPPmlND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}